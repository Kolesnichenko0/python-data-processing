{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "464d0afc-ff62-4125-ab10-09eaca1cff46",
   "metadata": {},
   "source": [
    "# **Labwork1. Exploring and visualising data with Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99996ea7-11a7-4239-848d-a31c4fa90ce2",
   "metadata": {},
   "source": [
    "## **Objective: to gain basic skills in using Python for data research and visualisation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5712c0-423e-40f7-a3d5-b84f9f878e56",
   "metadata": {},
   "source": [
    "## Task:\n",
    "1. Download the `russia_losses_equipment.csv` file from Kaggle.com  \n",
    "   [https://www.kaggle.com/datasets/piterfm/2022-ukraine-russian-war](https://www.kaggle.com/datasets/piterfm/2022-ukraine-russian-war)\n",
    "2. Choose one variant for this laboratory work, using the formula:  \n",
    "   **N = ord(\"LLL\") % 3 + 1**,  \n",
    "   where N is the variant number and LLL is the first letter of your name.\n",
    "3. Tips:  \n",
    "    a. Use the `csv.reader()` function to read the CSV file.  \n",
    "    b. Skip the first row (with column headers).  \n",
    "    c. Do not use loops or other iterative constructs for processing NumPy arrays. Use only slicing and/or universal (vectorized) functions.  \n",
    "    d. Create functions for tasks 3-7 for each variant.\n",
    "4. Requirements for plots:  \n",
    "   a. Set the line type (dashed, etc.);  \n",
    "   b. The plots should be labeled;  \n",
    "   c. Add a legend;  \n",
    "   d. Add a grid and specify the color and line type;  \n",
    "   e. Add a title to the plot, axis labels, and values on the axes;  \n",
    "   f. Change the size of the plot (e.g., 8x16 inches) and resolution (e.g., 100 dpi);  \n",
    "   g. Save the plot to a PNG file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbd1c73-98a5-4850-b608-5ae2e0a5b05d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "N = ord(\"D\") % 3 + 1\n",
    "print(f\"Denys Kolesnychenko's variant: {N}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d20cbc-d901-4e05-a6dc-aa67dd6564ef",
   "metadata": {},
   "source": [
    "## Variant 3. Study of Armored Personnel Carrier (APC) losses.\n",
    "1. Create a function that takes the filename and column name as parameters and returns a NumPy array with the column values.\n",
    "2. Using the function from the previous task, create a NumPy array with the values of the \"APC\" column (Armored Personnel Carrier).\n",
    "3. Calculate daily APC losses.\n",
    "4. Find the 5 highest daily APC losses.\n",
    "5. Determine how many APCs were destroyed in the summer of 2023.\n",
    "6. Find the average number of destroyed APCs over the 100-500 days of the war.\n",
    "7. Create a plot of APC losses for the last 200 days (starting from the last date in the dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba32f6c-6545-48d1-bcef-ad29f20a9a10",
   "metadata": {},
   "source": [
    "## Completion of the task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca6719d-67b4-4812-8ecc-b4cdf6a889ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime, date, timedelta\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "DATA_FOLDER_PATH = 'data'\n",
    "LOSSES_FILE_NAME = 'russia_losses_equipment.csv'\n",
    "LOSSES_FILE_PATH = os.path.join(DATA_FOLDER_PATH, LOSSES_FILE_NAME)\n",
    "LOSSES_COLUMN_NAME = 'APC'\n",
    "WAR_START_DATE = date(2022, 2, 24)\n",
    "# Task 5\n",
    "START_DATE = date(2023, 6, 1)\n",
    "END_DATE = date(2023, 8, 31)\n",
    "# Task 6\n",
    "START_DATE_NUMBER = 100\n",
    "END_DATE_NUMBER = 500\n",
    "# Task 7\n",
    "LAST_N_DAYS = 200\n",
    "RESULT_FOLDER_PATH = 'result'\n",
    "RESULT_FILE_NAME = f'{LOSSES_COLUMN_NAME}_losses_graph_{LAST_N_DAYS}_days.png'\n",
    "RESULT_FILE_PATH = os.path.join(RESULT_FOLDER_PATH, RESULT_FILE_NAME)\n",
    "\n",
    "\n",
    "def get_int_column_data_as_numpy_array(source_file, column_name):\n",
    "    if not os.path.exists(source_file):\n",
    "        raise FileNotFoundError(f\"File '{source_file}' not found.\")\n",
    "\n",
    "    try:\n",
    "        with open(source_file, 'r', encoding='utf-8') as file:\n",
    "            reader = csv.reader(file, delimiter=',')\n",
    "            headers = next(reader)\n",
    "\n",
    "            if column_name not in headers:\n",
    "                raise ValueError(f\"Column '{column_name}' not found in headers.\")\n",
    "\n",
    "            column_index = headers.index(column_name)\n",
    "\n",
    "            column_data = []\n",
    "\n",
    "            for row in reader:\n",
    "                value = row[column_index]\n",
    "                if value == \"\":\n",
    "                    raise ValueError(f\"Missing value in column '{column_name}' at line {reader.line_num}.\")\n",
    "                try:\n",
    "                    column_data.append(int(value))\n",
    "                except ValueError:\n",
    "                    raise ValueError(f\"Invalid value '{row[column_index]}' in column '{column_name}' at line {reader.line_num}.\")\n",
    "\n",
    "            column_data.append(0)\n",
    "\n",
    "            return np.array(column_data)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"File '{source_file}' cannot be opened.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    cumulative_losses_data = get_int_column_data_as_numpy_array(LOSSES_FILE_PATH, LOSSES_COLUMN_NAME)\n",
    "    print(f\"Cumulative {LOSSES_COLUMN_NAME} losses for each day of the war:\\n{cumulative_losses_data}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc748c-d92f-4988-b9fa-45f72a9c40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_daily_losses(cumulative_losses_data):\n",
    "    if len(cumulative_losses_data) < 2:\n",
    "        raise ValueError(\"Not enough data to calculate daily losses.\")\n",
    "\n",
    "    return -np.diff(cumulative_losses_data)\n",
    "\n",
    "\n",
    "try:\n",
    "    daily_losses_data = calculate_daily_losses(cumulative_losses_data)\n",
    "    print(f\"\\nDaily {LOSSES_COLUMN_NAME} losses:\\n{daily_losses_data}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e4f9a1-fe89-41b3-af50-6911c73500fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_losses(daily_losses_data, n=5):\n",
    "    if len(daily_losses_data) < n:\n",
    "        raise ValueError(f\"Not enough values. Requested {n}, available {len(daily_losses_data)}\")\n",
    "    return np.sort(daily_losses_data)[-1:-(n + 1):-1]\n",
    "\n",
    "\n",
    "def get_top_n_unique_losses(daily_losses_data, n=5):\n",
    "    unique_losses = np.unique(daily_losses_data)\n",
    "\n",
    "    if len(unique_losses) < n:\n",
    "        raise ValueError(f\"There are not enough unique values. Requested {n}, available {len(unique_losses)}\")\n",
    "\n",
    "    top_n_unique = get_top_n_losses(unique_losses, n)\n",
    "\n",
    "    return top_n_unique\n",
    "\n",
    "\n",
    "try:\n",
    "    top_5_losses = get_top_n_losses(daily_losses_data)\n",
    "    print(f\"\\nTop 5 daily {LOSSES_COLUMN_NAME} losses:\\n{top_5_losses}\")\n",
    "\n",
    "    top_5_unique_losses = get_top_n_unique_losses(daily_losses_data)\n",
    "    print(f\"\\nTop 5 unique daily {LOSSES_COLUMN_NAME} losses:\\n{top_5_unique_losses}\")\n",
    "\n",
    "    top_10_losses = get_top_n_losses(daily_losses_data, 10)\n",
    "    print(f\"\\nTop 10 daily {LOSSES_COLUMN_NAME} losses:\\n{top_10_losses}\")\n",
    "\n",
    "    top_10_unique_losses = get_top_n_unique_losses(daily_losses_data, 10)\n",
    "    print(f\"\\nTop 10 unique daily {LOSSES_COLUMN_NAME} losses:\\n{top_10_unique_losses}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5686ee9-3d66-4733-8065-6a4fb3f5bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_period_indices(start_day_number, end_day_number, data_length):\n",
    "    if start_day_number <= 0:\n",
    "        raise ValueError(\"Start day index is out of bounds (should be > 0)\")\n",
    "    if end_day_number >= data_length:\n",
    "        raise ValueError(\"End day index is out of bounds (should be < length of data)\")\n",
    "    if start_day_number > end_day_number:\n",
    "        raise ValueError(\"Start day index is greater than end day index\")\n",
    "\n",
    "\n",
    "def calculate_war_day(specific_date, war_start_date):\n",
    "    if isinstance(specific_date, datetime):\n",
    "        specific_date = specific_date.date()\n",
    "    elif not isinstance(specific_date, date):\n",
    "        raise ValueError(\"specific_date must be a date or datetime object\")\n",
    "\n",
    "    if specific_date < war_start_date:\n",
    "        raise ValueError(\"The date can't be earlier than the start of the war\")\n",
    "\n",
    "    days_passed = (specific_date - war_start_date).days + 1\n",
    "    return days_passed\n",
    "\n",
    "\n",
    "def calculate_losses_for_period(cumulative_losses_data, start_day_number, end_day_number):\n",
    "    validate_period_indices(start_day_number, end_day_number, len(cumulative_losses_data))\n",
    "\n",
    "    start_index = len(cumulative_losses_data) - start_day_number\n",
    "    end_index = len(cumulative_losses_data) - end_day_number - 1\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    losses = cumulative_losses_data[end_index] - cumulative_losses_data[start_index]\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    print(f\"Execution time(calculate_losses_for_period): {(end_time - start_time):.6f}\")\n",
    "    return losses\n",
    "\n",
    "\n",
    "def calculate_losses_sum_for_period(daily_losses_data, start_day_number, end_day_number):\n",
    "    validate_period_indices(start_day_number, end_day_number, len(daily_losses_data))\n",
    "\n",
    "    start_index = len(daily_losses_data) - start_day_number + 1\n",
    "    end_index = len(daily_losses_data) - end_day_number\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    total_losses = np.sum(daily_losses_data[end_index:start_index])\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    print(f\"Execution time(calculate_losses_sum_for_period): {(end_time - start_time):.6f}\")\n",
    "    return total_losses\n",
    "\n",
    "\n",
    "try:\n",
    "    print(\"\\nUsing calculate_losses_for_period:\")\n",
    "    period_losses = calculate_losses_for_period(cumulative_losses_data, \n",
    "                                                calculate_war_day(START_DATE, WAR_START_DATE), \n",
    "                                                calculate_war_day(END_DATE, WAR_START_DATE))\n",
    "    print(f\"{LOSSES_COLUMN_NAME} losses from {START_DATE} to {END_DATE}: {period_losses}\")\n",
    "\n",
    "    print(\n",
    "        \"\\nUsing calculate_losses_sum_for_period:\")\n",
    "    period_losses_sum = calculate_losses_sum_for_period(daily_losses_data, \n",
    "                                                        calculate_war_day(START_DATE, WAR_START_DATE), \n",
    "                                                        calculate_war_day(END_DATE, WAR_START_DATE))\n",
    "    print(f\"{LOSSES_COLUMN_NAME} losses from {START_DATE} to {END_DATE}: {period_losses_sum}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f82c84-cbd7-428e-896a-c8b0652c3377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_losses_for_period(cumulative_losses_data, start_day_number, end_day_number):\n",
    "    validate_period_indices(start_day_number, end_day_number, len(cumulative_losses_data))\n",
    "\n",
    "    start_index = len(cumulative_losses_data) - start_day_number\n",
    "    end_index = len(cumulative_losses_data) - end_day_number - 1\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    losses = cumulative_losses_data[end_index] - cumulative_losses_data[start_index]\n",
    "    average_losses = losses / (end_day_number - start_day_number + 1)\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    print(f\"Execution time(calculate_average_losses_for_period): {(end_time - start_time):.6f}\")\n",
    "    return average_losses\n",
    "\n",
    "\n",
    "def calculate_average_losses_sum_for_period(daily_losses_data, start_day_number, end_day_number):\n",
    "    validate_period_indices(start_day_number, end_day_number, len(daily_losses_data))\n",
    "\n",
    "    start_index = len(daily_losses_data) - start_day_number + 1\n",
    "    end_index = len(daily_losses_data) - end_day_number\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    average_losses = np.mean(daily_losses_data[end_index:start_index])\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    print(f\"Execution time(calculate_average_losses_sum_for_period): {(end_time - start_time):.6f}\")\n",
    "    return average_losses\n",
    "\n",
    "\n",
    "try:\n",
    "    print(\"\\nUsing calculate_average_losses_for_period:\")\n",
    "    average_losses = calculate_average_losses_for_period(cumulative_losses_data, START_DATE_NUMBER, END_DATE_NUMBER)\n",
    "    print(f\"Average {LOSSES_COLUMN_NAME} losses from day {START_DATE_NUMBER} to day {END_DATE_NUMBER}: {average_losses:.2f}\")\n",
    "\n",
    "    print(\"\\nUsing calculate_average_losses_sum_for_period:\")\n",
    "    average_losses_sum = calculate_average_losses_sum_for_period(daily_losses_data, START_DATE_NUMBER, END_DATE_NUMBER)\n",
    "    print(f\"Average {LOSSES_COLUMN_NAME} losses from day {START_DATE_NUMBER} to day {END_DATE_NUMBER}: {average_losses_sum:.2f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b3254-b6db-4c52-a69d-a80198a84469",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "\n",
    "def get_latest_date(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File '{file_path}' not found.\")\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            reader = csv.reader(file)\n",
    "            headers = next(reader)\n",
    "            date_index = headers.index('date')\n",
    "            first_row = next(reader)\n",
    "            latest_date = datetime.strptime(first_row[date_index], '%Y-%m-%d').date()\n",
    "            return latest_date\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"File '{file_path}' cannot be opened.\")\n",
    "\n",
    "\n",
    "def prepare_data_for_graph(file_path, cumulative_losses_data, last_n_days):\n",
    "    latest_date = get_latest_date(file_path)\n",
    "    start_date = latest_date - timedelta(days=last_n_days - 1)\n",
    "    dates = [(start_date + timedelta(days=i)) for i in range(last_n_days)]\n",
    "    last_n_days_cumulative_losses = cumulative_losses_data[last_n_days - 1::-1]\n",
    "    return dates, last_n_days_cumulative_losses\n",
    "\n",
    "\n",
    "def plot_cumulative_losses(dates, last_n_days_cumulative_losses, result_file, column_name, last_n_days):\n",
    "    plt.figure(figsize=(10, 12), dpi=100)\n",
    "    plt.plot(dates, last_n_days_cumulative_losses, linestyle='--', color='blue', label=f'{column_name} cumulative losses')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "    xticks = ax.get_xticks()\n",
    "    new_ticks = np.array([mdates.date2num(dates[0]), mdates.date2num(dates[-1])])\n",
    "    combined_xticks = np.concatenate((xticks, new_ticks))\n",
    "    xticklabels = [tick.get_text() for tick in ax.get_xticklabels()]\n",
    "    combined_xticklabels = xticklabels + [dates[0].strftime('%Y-%m-%d'), dates[-1].strftime('%Y-%m-%d')]\n",
    "    ax.set_xticks(combined_xticks)\n",
    "    ax.set_xticklabels(combined_xticklabels, rotation=45)\n",
    "\n",
    "    x_range = mdates.date2num(dates[-1]) - mdates.date2num(dates[0])\n",
    "    x_buffer = x_range * 0.03\n",
    "    ax.set_xlim(mdates.num2date(mdates.date2num(dates[0]) - x_buffer),\n",
    "                mdates.num2date(mdates.date2num(dates[-1]) + x_buffer))\n",
    "\n",
    "    yticks = ax.get_yticks()\n",
    "    new_ticks = np.array([min(last_n_days_cumulative_losses), max(last_n_days_cumulative_losses)])\n",
    "    combined_ticks = np.concatenate((yticks, new_ticks))\n",
    "    ax.set_yticks(combined_ticks)\n",
    "    ax.set_yticklabels([f'{int(tick)}' for tick in combined_ticks])\n",
    "\n",
    "    y_buffer = (max(last_n_days_cumulative_losses) - min(last_n_days_cumulative_losses)) * 0.03\n",
    "    ax.set_ylim(min(last_n_days_cumulative_losses) - y_buffer, max(last_n_days_cumulative_losses) + y_buffer)\n",
    "\n",
    "    plt.title(f'{column_name} losses in the last {last_n_days} days',\n",
    "              fontsize=16, fontweight='bold', color='darkred', pad=20)\n",
    "    plt.xlabel('Date', fontsize=12, labelpad=15, fontweight='bold')\n",
    "    plt.ylabel('Cumulative losses', fontsize=12, labelpad=15, fontweight='bold')\n",
    "\n",
    "    plt.grid(True, linestyle='--', color='darkgray', alpha=0.5)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(result_file)\n",
    "    print(f\"\\nThe graph is saved to a file: {result_file}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "try:\n",
    "    dates, last_n_days_cumulative_losses = prepare_data_for_graph(LOSSES_FILE_PATH, cumulative_losses_data, LAST_N_DAYS)\n",
    "    plot_cumulative_losses(dates, last_n_days_cumulative_losses, RESULT_FILE_PATH, LOSSES_COLUMN_NAME, LAST_N_DAYS)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f361ff42-d427-40be-a9c2-4d80e6351cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
